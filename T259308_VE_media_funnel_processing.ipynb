{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Editor Media Search Editing Funnel\n",
    "\n",
    "This notebook is expected to be run daily and will update a staging table in the Data Lake with aggregate statistics on the Media funnel in Visual Editor. It expects all relevant data for that day to be present, meaning that it should be run at least four hours after midnight UTC (we know that it takes 2â€“3 hours for data to get there). Specifically, the goal is to be able to answer what percentage of searches for media in VE leads to the subsequent addition of a media file to the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from wmfdata import spark, mariadb\n",
    "from growth import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the table in the Data Lake\n",
    "\n",
    "table_name = 'nettrom_sd.ve_media_funnel_aggregates'\n",
    "\n",
    "# Values of the `action` field for opening and closing the media dialog for the\n",
    "# two paths.\n",
    "dialog_actions = {\n",
    "    'add media' : {\n",
    "        'open' : 'window-open-from-tool',\n",
    "        'close' : 'dialog-insert'\n",
    "    },\n",
    "    'edit media' : {\n",
    "        'open' : 'window-open-from-context',\n",
    "        'close' : 'dialog-done'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_partition_statement(start_ts, end_ts, prefix = ''):\n",
    "    '''\n",
    "    This takes the two timestamps and creates a statement that selects\n",
    "    partitions based on `year`, `month`, and `day` in order to make our\n",
    "    data gathering not use excessive amounts of data. It assumes that\n",
    "    `start_ts` and `end_ts` are not more than a month apart, which should\n",
    "    be a reasonable expectation for this notebook.\n",
    "    \n",
    "    An optional prefix can be set to enable selecting partitions for\n",
    "    multiple tables with different aliases.\n",
    "    \n",
    "    :param start_ts: start timestamp\n",
    "    :type start_ts: datetime.datetime\n",
    "    \n",
    "    :param end_ts: end timestamp\n",
    "    :type end_ts: datetime.datetime\n",
    "    \n",
    "    :param prefix: prefix to use in front of partition clauses, \".\" is added automatically\n",
    "    :type prefix: str\n",
    "    '''\n",
    "    \n",
    "    if prefix:\n",
    "        prefix = f'{prefix}.' # adds \".\" after the prefix\n",
    "    \n",
    "    # there are three cases:\n",
    "    # 1: month and year are the same, output a \"BETWEEN\" statement with the days\n",
    "    # 2: months differ, but the years are the same.\n",
    "    # 3: years differ too.\n",
    "    # Case #2 and #3 can be combined, because it doesn't really matter\n",
    "    # if the years are the same in the month-selection or not.\n",
    "    \n",
    "    if start_ts.year == end_ts.year and start_ts.month == end_ts.month:\n",
    "        return(f'''{prefix}year = {start_ts.year}\n",
    "AND {prefix}month = {start_ts.month}\n",
    "AND {prefix}day BETWEEN {start_ts.day} AND {end_ts.day}''')\n",
    "    else:\n",
    "        return(f'''\n",
    "(\n",
    "    ({prefix}year = {start_ts.year}\n",
    "     AND {prefix}month = {start_ts.month}\n",
    "     AND {prefix}day >= {start_ts.day})\n",
    " OR ({prefix}year = {end_ts.year}\n",
    "     AND {prefix}month = {end_ts.month}\n",
    "     AND {prefix}day <= {end_ts.day})\n",
    ")''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Needs\n",
    "\n",
    "What exactly does the funnel look like?\n",
    "\n",
    "* Starts editing.\n",
    "* Opens the media dialog to add an image, opens the media dialog to edit an image.\n",
    "* Searches for an image, or uploads an image.\n",
    "* Confirms the image.\n",
    "* Closes the dialog to add the image, closes the dialog to replace an existing image.\n",
    "* Saves the edit.\n",
    "\n",
    "Note that the main thing we're focused on is the use of MediaSearch to *search* for images, and then whether that search leads to an image being *used* (either added to the article, or replacing an existing image).\n",
    "\n",
    "I'm going to interpret that to mean that we're not focused on the uploading path, and that we'll ignore it. When it comes to the \"add an image\" and \"replace an image\" paths, I want to see them as two distinct paths. Again, the focus here is on the \"is the image being used\" part of the path (i.e. \"was the search successful?\"), so that a user can both add and edit images in the same edit session doesn't really matter.\n",
    "\n",
    "What do we need to store?\n",
    "\n",
    "* Date\n",
    "* Namespace\n",
    "* The path taken: \"add media\" or \"edit existing media\"\n",
    "* Step 1: number of edit sessions.\n",
    "* Step 2: opens the media dialog.\n",
    "* Step 3: Searches for an image.\n",
    "* Step 4: Confirms the image.\n",
    "* Step 5: Closes the dialog.\n",
    "* Step 6: Saves the edit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Creation\n",
    "\n",
    "This is for reference, reflecting the `CREATE TABLE` statement used to create the dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "create_table_statement = '''\n",
    "CREATE TABLE {aggregate_table}\n",
    "(\n",
    "    log_date DATE COMMENT \"the date of the aggregated edit sessions\",\n",
    "    namespace INT COMMENT \"the numeric namespace that was edited\",\n",
    "    path_type STRING COMMENT \"the type of path, either 'add media' or 'edit media'\",\n",
    "    num_edit_sessions BIGINT COMMENT \"Step 1: the number of edit sessions started\",\n",
    "    num_dialog_opens BIGINT COMMENT \"Step 2: the number sessions where the media dialog was opened\",\n",
    "    num_media_searches BIGINT COMMENT \"Step 3: the number of sessions where a search was made\",\n",
    "    num_media_confirms BIGINT COMMENT \"Step 4: the number of sessions confirming media\",\n",
    "    num_dialog_close BIGINT COMMENT \"Step 5: the number of sessions closing the dialog to add/replace media\",\n",
    "    num_edit_saves BIGINT COMMENT \"Step 6: the number of sessions with saved edits\"\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(create_table_statement.format(aggregate_table = table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dates and Timestamp Limit\n",
    "\n",
    "We'll grab today's date, figure out what yesterday was (the day we're grabbing data for), and set a limit to one hour after midnight today. All in UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.datetime.now(dt.timezone.utc).date()\n",
    "yesterday = today - dt.timedelta(days = 1)\n",
    "\n",
    "limit_timestamp = dt.datetime.combine(today, dt.time(hour = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funnel Query\n",
    "\n",
    "This query is the same for both paths, but the \"open media dialog\" and \"close media dialog\" actions differ. In the \"add media\" path the open action is `window-open-from-tool` and the close action is `dialog-insert`, in the \"edit media\" path they're `window-open-from-context` and `dialog-done`, respectively.\n",
    "\n",
    "We use partitions and timestamps to limit when edit sessions were initiated to only count edit sessions that started within the day we're aggregating over. We allow the sessions to be completed within one hour *after* the end of this day.\n",
    "\n",
    "We originally used differences in the values in `dt` to determine order in the funnel. This turned out to not work as desired, because too many events appear to occur quickly enough for the events to have the same timestamp. There's a separate notebook that investigates this in more detail. The conclusion of that analysis is that we cannot require the difference between two events to be greater than 0 at any point in the funnel. But, we'll require it to be non-negative, because anything else would not make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_funnel_query = '''\n",
    "WITH step_1 AS ( -- Number of VE edit sessions, \n",
    "    SELECT\n",
    "        event.editing_session_id,\n",
    "        FIRST_VALUE(event.page_ns) AS namespace,\n",
    "        MIN(dt) AS dt\n",
    "    FROM event.editattemptstep AS es\n",
    "    WHERE {es_partition_statement}\n",
    "    AND dt >= \"{start_date}\"\n",
    "    AND dt < \"{end_date}\"\n",
    "    AND event.is_oversample = false\n",
    "    AND event.editor_interface = \"visualeditor\"\n",
    "    AND event.action = \"init\"\n",
    "    GROUP BY event.editing_session_id\n",
    "),\n",
    "step_2 AS ( -- Open the media dialog\n",
    "    SELECT\n",
    "        vefu.event.editingsessionid AS editing_session_id,\n",
    "        MIN(vefu.dt) AS dt\n",
    "    FROM step_1\n",
    "    INNER JOIN event.visualeditorfeatureuse AS vefu\n",
    "    ON step_1.editing_session_id = vefu.event.editingsessionid\n",
    "    WHERE {vefu_partition_statement}\n",
    "    AND vefu.event.feature = \"media\"\n",
    "    AND vefu.event.action = \"{open_action}\"\n",
    "    AND vefu.dt >= step_1.dt\n",
    "    AND vefu.dt < \"{time_limit_ts}\"\n",
    "    GROUP BY vefu.event.editingsessionid\n",
    "),\n",
    "step_3 AS ( -- Search for media\n",
    "    SELECT\n",
    "        vefu.event.editingsessionid AS editing_session_id,\n",
    "        MIN(vefu.dt) AS dt\n",
    "    FROM step_2\n",
    "    INNER JOIN event.visualeditorfeatureuse AS vefu\n",
    "    ON step_2.editing_session_id = vefu.event.editingsessionid\n",
    "    WHERE {vefu_partition_statement}\n",
    "    AND vefu.event.feature = \"media\"\n",
    "    AND vefu.event.action = \"search-change-query\"\n",
    "    AND vefu.dt >= step_2.dt\n",
    "    AND vefu.dt < \"{time_limit_ts}\"\n",
    "    GROUP BY vefu.event.editingsessionid\n",
    "),\n",
    "step_4 AS ( -- Confirm a search result\n",
    "    SELECT\n",
    "        vefu.event.editingsessionid AS editing_session_id,\n",
    "        MIN(vefu.dt) AS dt\n",
    "    FROM step_3\n",
    "    INNER JOIN event.visualeditorfeatureuse AS vefu\n",
    "    ON step_3.editing_session_id = vefu.event.editingsessionid\n",
    "    WHERE {vefu_partition_statement}\n",
    "    AND vefu.event.feature = \"media\"\n",
    "    AND vefu.event.action = \"search-confirm-image\"\n",
    "    AND vefu.dt >= step_3.dt\n",
    "    AND vefu.dt < \"{time_limit_ts}\"\n",
    "    GROUP BY vefu.event.editingsessionid\n",
    "),\n",
    "step_5 AS ( -- Close the media dialog\n",
    "    SELECT\n",
    "        vefu.event.editingsessionid AS editing_session_id,\n",
    "        MIN(vefu.dt) AS dt\n",
    "    FROM step_4\n",
    "    INNER JOIN event.visualeditorfeatureuse AS vefu\n",
    "    ON step_4.editing_session_id = vefu.event.editingsessionid\n",
    "    WHERE {vefu_partition_statement}\n",
    "    AND vefu.event.feature = \"media\"\n",
    "    AND vefu.event.action = \"{close_action}\"\n",
    "    AND vefu.dt >= step_4.dt\n",
    "    AND vefu.dt < \"{time_limit_ts}\"\n",
    "    GROUP BY vefu.event.editingsessionid\n",
    "),\n",
    "step_6 AS ( -- Save the edit\n",
    "    SELECT\n",
    "        DISTINCT es.event.editing_session_id\n",
    "    FROM step_5\n",
    "    INNER JOIN event.editattemptstep AS es\n",
    "    ON step_5.editing_session_id = es.event.editing_session_id\n",
    "    WHERE {es_partition_statement}\n",
    "    AND es.event.action = \"saveSuccess\"\n",
    "    AND es.dt >= step_5.dt\n",
    "    AND es.dt < \"{time_limit_ts}\"\n",
    ")\n",
    "INSERT INTO {aggregate_table}\n",
    "SELECT\n",
    "    TO_DATE(step_1.dt) AS log_date,\n",
    "    step_1.namespace,\n",
    "    \"{path_type}\" AS path_type,\n",
    "    count(1) AS num_edit_sessions,\n",
    "    SUM(IF(step_2.editing_session_id IS NOT NULL, 1, 0)) AS num_dialog_opens,\n",
    "    count(step_3.editing_session_id) AS num_media_searches,\n",
    "    count(step_4.editing_session_id) AS num_media_confirms,\n",
    "    count(step_5.editing_session_id) AS num_dialog_close,\n",
    "    count(step_6.editing_session_id) AS num_edit_saves\n",
    "FROM step_1\n",
    "LEFT JOIN step_2\n",
    "ON step_1.editing_session_id = step_2.editing_session_id\n",
    "LEFT JOIN step_3\n",
    "ON step_1.editing_session_id = step_3.editing_session_id\n",
    "LEFT JOIN step_4\n",
    "ON step_1.editing_session_id = step_4.editing_session_id\n",
    "LEFT JOIN step_5\n",
    "ON step_1.editing_session_id = step_5.editing_session_id\n",
    "LEFT JOIN step_6\n",
    "ON step_1.editing_session_id = step_6.editing_session_id\n",
    "GROUP BY TO_DATE(step_1.dt), step_1.namespace\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(edit_funnel_query.format(\n",
    "        start_date = yesterday,\n",
    "        end_date = today,\n",
    "        time_limit_ts = limit_timestamp.isoformat(),\n",
    "        es_partition_statement = make_partition_statement(yesterday, today, prefix = 'es'),\n",
    "        vefu_partition_statement = make_partition_statement(yesterday, today, prefix = 'vefu'),\n",
    "        aggregate_table = table_name,\n",
    "        path_type = 'add media',\n",
    "        open_action = dialog_actions['add media']['open'],\n",
    "        close_action = dialog_actions['add media']['close']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/bin/python3.7.\n",
      "PySpark executors will use /usr/bin/python3.7.\n"
     ]
    }
   ],
   "source": [
    "for path_type in dialog_actions.keys():\n",
    "    try:\n",
    "        query_result = spark.run(\n",
    "            edit_funnel_query.format(\n",
    "                start_date = yesterday,\n",
    "                end_date = today,\n",
    "                time_limit_ts = limit_timestamp.isoformat(),\n",
    "                es_partition_statement = make_partition_statement(yesterday, today, prefix = 'es'),\n",
    "                vefu_partition_statement = make_partition_statement(yesterday, today, prefix = 'vefu'),\n",
    "                aggregate_table = table_name,\n",
    "                path_type = path_type,\n",
    "                open_action = dialog_actions[path_type]['open'],\n",
    "                close_action = dialog_actions[path_type]['close']\n",
    "            )\n",
    "        )\n",
    "    except UnboundLocalError:\n",
    "        # wmfdata currently (late Feb 2021) has an issue with DDL/DML SQL queries,\n",
    "        # and so we ignore that error\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the queries run, then run this command to set the permissions on the table correctly so others can query it: `hdfs dfs -chmod -R o+r <path to your table>`\n",
    "This is taken care of the shell script that runs this notebook every day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
